{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "minst=tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images, test_labels)=minst.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7effbd221970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy') >= 0.99): # Experiment with changing this value\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
    "                          tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                          tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4752 - accuracy: 0.8285\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3569 - accuracy: 0.8690\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3221 - accuracy: 0.8791\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2951 - accuracy: 0.8911\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2793 - accuracy: 0.8950\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2631 - accuracy: 0.9008\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2500 - accuracy: 0.9065\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2381 - accuracy: 0.9105\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2274 - accuracy: 0.9143\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2168 - accuracy: 0.9172\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2110 - accuracy: 0.9204\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2028 - accuracy: 0.9239\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1949 - accuracy: 0.9272\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1876 - accuracy: 0.9295\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1818 - accuracy: 0.9316\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1739 - accuracy: 0.9345\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1730 - accuracy: 0.9348\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1632 - accuracy: 0.9391\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1603 - accuracy: 0.9391\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1543 - accuracy: 0.9426\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1527 - accuracy: 0.9423\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1474 - accuracy: 0.9439\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1392 - accuracy: 0.9471\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1383 - accuracy: 0.9479\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1377 - accuracy: 0.9485\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1308 - accuracy: 0.9503\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1297 - accuracy: 0.9502\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1251 - accuracy: 0.9525\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1255 - accuracy: 0.9534\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1198 - accuracy: 0.9554\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1173 - accuracy: 0.9561\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1132 - accuracy: 0.9570\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1149 - accuracy: 0.9566\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1076 - accuracy: 0.9598\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1069 - accuracy: 0.9599\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1052 - accuracy: 0.9607\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1005 - accuracy: 0.9625\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0994 - accuracy: 0.9618\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0988 - accuracy: 0.9635\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0977 - accuracy: 0.9625\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0920 - accuracy: 0.9646\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0919 - accuracy: 0.9654\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0918 - accuracy: 0.9655\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0887 - accuracy: 0.9665\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0869 - accuracy: 0.9679\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0861 - accuracy: 0.9673\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0840 - accuracy: 0.9686\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0819 - accuracy: 0.9696\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0800 - accuracy: 0.9694\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0799 - accuracy: 0.9703\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0766 - accuracy: 0.9713\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0787 - accuracy: 0.9704\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0794 - accuracy: 0.9712\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0735 - accuracy: 0.9727\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0759 - accuracy: 0.9720\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0712 - accuracy: 0.9740\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0692 - accuracy: 0.9749\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0698 - accuracy: 0.9740\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0694 - accuracy: 0.9749\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0662 - accuracy: 0.9755\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0692 - accuracy: 0.9751\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0653 - accuracy: 0.9760\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0634 - accuracy: 0.9766\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0593 - accuracy: 0.9775\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0675 - accuracy: 0.9757\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0614 - accuracy: 0.9776\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0633 - accuracy: 0.9764\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0614 - accuracy: 0.9765\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0563 - accuracy: 0.9790\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0583 - accuracy: 0.9782\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0606 - accuracy: 0.9784\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0572 - accuracy: 0.9789\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0592 - accuracy: 0.9783\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0558 - accuracy: 0.9794\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0554 - accuracy: 0.9809\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0566 - accuracy: 0.9794\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0553 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0486 - accuracy: 0.9815\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0507 - accuracy: 0.9812\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0539 - accuracy: 0.9798\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0522 - accuracy: 0.9811\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0501 - accuracy: 0.9816\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0519 - accuracy: 0.9810\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0471 - accuracy: 0.9831\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0535 - accuracy: 0.9810\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0468 - accuracy: 0.9835\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0518 - accuracy: 0.9818\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0449 - accuracy: 0.9834\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0481 - accuracy: 0.9825\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0478 - accuracy: 0.9826\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0421 - accuracy: 0.9845\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0482 - accuracy: 0.9827\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0430 - accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0476 - accuracy: 0.9829\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0424 - accuracy: 0.9847\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0501 - accuracy: 0.9826\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0392 - accuracy: 0.9856\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0444 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0427 - accuracy: 0.9843\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0418 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7eff6cc19a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks=myCallback()\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels,epochs=100, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.8808 - accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8808402419090271, 0.8988999724388123]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 1.7715001e-38 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.3844222e-23 0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3340434e-24]\n"
     ]
    }
   ],
   "source": [
    "classification=model.predict(test_images)\n",
    "print(classification[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
